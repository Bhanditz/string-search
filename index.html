<!DOCTYPE html>
<html dir="ltr" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>String Searching</title>
    <!--<link rel="canonical" href="http://www.w3.org/TR/2015/WD-string-search-20151119/"/> -->
    <!-- local styles. Includes the styles from http://www.w3.org/International/docs/styleguide -->
    <link rel="stylesheet" href="local.css" type="text/css">
	<script src="https://www.w3.org/Tools/respec/respec-w3c-common" async class="remove"></script>
    <script class="remove">
      var respecConfig = {
          useExperimentalStyles: true,
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:				"ED",
          //publishDate:  			"2016-09-29",
          //previousMaturity:  		"ED",

          noRecTrack:           true,
          shortName:            "string-search",
          copyrightStart: 		"2016",
          edDraftURI:   		"http://w3c.github.io/string-search/",

          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              { name: "Addison Phillips", 
                company: "Invited Expert",
				w3cid: 33573 },
          ],

          // authors, add as many as you like. 
          //authors:  [
          //    { name: "Your Name", url: "http://example.org/",
          //      company: "Your Company", companyURL: "http://example.com/" },
          //],
          
          // name of the WG
          wg:           "Internationalization Working Group",
          wgURI:        "http://www.w3.org/International/core/",
          wgPublicList: "www-international",
          
		  bugTracker: { new: "https://github.com/w3c/string-search/issues", open: "https://github.com/w3c/string-search/issues" } ,
		otherLinks: [
			{
			key: "Github",
			data: [
				{
			  	value: "repository",
			  	href: "https://github.com/w3c/string-search/"
		 		}
				]
			}
			],

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "http://www.w3.org/2004/01/pp-impl/32113/status",
		  

		  localBiblio: {
		"UTS18": {
		    title: "Unicode Technical Standard #18: Unicode Regular Expressions",
			href: "http://unicode.org/reports/tr18/",
			authors: [ "Mark Davis", "Andy Heninger" ]
		},
		
		"Encoding": {
			title: "Encoding",
			href: "http://www.w3.org/TR/encoding/",
			authors: [ "Anne van Kesteren", "Joshua Bell", "Addison Phillips" ]
		},
		
		"UTS10": {
			title: "Unicode Technical Standard #10: Unicode Collation Algorithm",
			href: "http://www.unicode.org/reports/tr10/",
			authors: [ "Mark Davis", "Ken Whistler", "Markus Scherer" ]
		},
		
		"UAX11": {
		    title: "Unicode Standard Annex #11: East Asian Width",
		    href: "http://www.unicode.org/reports/tr11/",
		    authors: [ "Ken Lunde å°æž—åŠ" ]
		},
		
		"UAX29": {
			title: "Unicode Standard Annex #29: Unicode Text Segmentation",
			href: "http://www.unicode.org/reports/tr29/",
			authors: [ "Mark Davis" ]
		},
		
		"UTS39": {
		    title: "Unicode Technical Standard #39: Unicode Security Mechanisms",
		    href: "http://www.unicode.org/reports/tr39/",
		    authors: [ "Mark Davis", "Michel Suignard" ]
		},
		
		"UTR36": {
			title: "Unicode Technical Report #36: Unicode Security Considerations",
			href: "http://www.unicode.org/reports/tr36/",
			authors: [ "Mark Davis", "Michel Suignard" ]
		},
		
		"UTR50": {
		    title: "Unicode Technical Report #50: Unicode Vertical Text Layout",
		    href: "http://www.unicode.org/reports/tr50/",
		    authors: [ "Koji Ishii çŸ³äº•å®æ²»" ]
		},
		
		"Nicol": {
			title: "The Multilingual World Wide Web, Chapter 2: The WWW As A Multilingual Application",
			href: "http://www.mind-to-mind.com/i18n/multilingual-www.html",
			authors: [ "Gavin Nicol" ]
		}
		
	}
		  
      };
	  

</script> </head>
  <body>
    <section id="abstract">
      <p>This document describes string searching operations on the Web in order 
	  to allow greater interoperability. String searching refers to natural 
	  language string matching such as the "find" command in a Web browser. This 
	  document builds upon the concepts found in <cite>Character Model for the 
	  World Wide Web 1.0: Fundamentals </cite>[[!CHARMOD]] and <cite>Character 
	  Model for the World Wide Web 1.0: String Matching</cite> [[!CHARMOD-NORM]] 
	  to provide authors of specifications, software developers, and content 
	  developers the information they need to describe and implement search 
	  features suitable for global audiences. </p>
    </section>
    <section id="sotd">
      <div class="note">
        <p data-lang="en" style="font-weight: bold; font-size: 120%">Sending 
		comments on this document</p>
        <p data-lang="en">If you wish to make comments regarding this document, 
		please raise them as <a href="https://github.com/w3c/string-search/issues"

            style="font-size: 120%;">github issues</a> against the lasted <a href="https://w3c.github.io/string-search">
		editor's copy</a>. Only send comments by email if you are unable to 
		raise issues on github (see links below). All comments are welcome.</p>
        <p data-lang="en">To make it easier to track comments, please raise 
		separate issues or emails for each comment, and point to the section you 
		are commenting on using a URL.</p>
      </div>
    </section>
    <section id="intro">
      <h2>Introduction</h2>
      <section id="goals">
        <h3>Goals and Scope</h3>
        <p>This document describes string searching—the process by which a 
		specification or implementation matches a natural language string 
		fragment against a specific document or series of documents. A common 
		example of string searching is the "find" command in a Web browser, but 
		there are many other forms of searching that a specification might wish 
		to define. </p>
        <p class="note">This document builds on <cite>Character Model for the 
		World Wide Web: Fundamentals</cite> [[!CHARMOD]] and <cite>Character 
		Model for the Word Wide Web: String Matching</cite> [[!CHARMOD-NORM]]. 
		Understanding the concepts in those documents are important to being 
		able to understand and apply this document successfully.</p>
        <p>The main target audience of this specification is W3C specification 
		developers who need to define some form of search or find algorithm: the 
		goal is to provide a stable reference to the concepts, terms, and 
		requirements needed.</p>
        <p>The concepts described in this document provide authors of 
		specifications, software developers, and content developers with a 
		common reference for consistent, interoperable text searching on the 
		World Wide Web. Working together, these three groups can build a 
		globally accessible Web.</p>
      </section>
      <section id="background">
        <h3>Background</h3>
        <p>At the core of the character model is the Universal Character Set 
		(UCS), defined jointly by the <cite>Unicode Standard</cite>
          [[!Unicode]] and ISO/IEC 10646 [[!ISO10646]]. In this document, <dfn>
		Unicode</dfn>
          is used as a synonym for the Universal Character Set. A successful 
		character model allows Web documents authored in the world's writing 
		systems, scripts, and languages (and on different platforms) to be 
		exchanged, read, and searched by the Web's users around the world.</p>
        <p>The first few chapters of the <cite>Unicode Standard</cite>
          [[!Unicode]] provide useful background reading. In particular, the 
		<cite>Unicode Collation Algorithm</cite> [[!UTS10]] contains a chapter 
		on searching.</p>
      </section>
      <section id="terminology">
        <h3>Terminology and Notation</h3>
        <p>This section contains terminology and notation specific to this 
		document.</p>
        <p>The Web is built on text-based formats and protocols. In order to 
		describe string matching or searching effectively, it is necessary to 
		establish terminology that allows us to talk about the different kinds 
		of text within a given format or protocol, as the requirements and 
		details vary significantly. </p>
        <p>Unicode code points are denoted as <code class="kw" translate="no">
		U+hhhh</code>, where <code class="kw" translate="no">hhhh</code> is a 
		sequence of at least four, and at most six hexadecimal digits. For 
		example, the character <span class="qchar">&#x20ac;</span> <span class="uname" translate="no">
		EURO SIGN</span> has the code point <span class="uname" translate="no">
		U+20AC</span>.</p>
        <p>Some characters that are used in the various examples might not 
		appear as intended unless you have the appropriate font. Care has been 
		taken to ensure that the examples nevertheless remain understandable.</p>
        <p>A <dfn data-lt="legacy character encoding|legacy character encodings">
		legacy character encoding</dfn> is a character encoding not based on the 
		Unicode character set.</p>
          
                   
        <p>A <dfn data-lt="transcoder|transcoders">transcoder</dfn> is a process 
		that converts text between two character encodings. Most commonly in 
		this document it refers to a process that converts from a <a>legacy 
		character encoding</a> 
        to a <a href="http://www.w3.org/TR/2005/REC-charmod-20050215/#Unicode_Encoding_Form">
		Unicode encoding form</a>, such as UTF-8.</p>
        <p><dfn id="def_syntactic_content">Syntactic content</dfn> is any text 
		in a document format or protocol that belongs to the structure of the 
		format or protocol. This definition can include values that are not 
		typically thought of as "markup", such as the name of a field in an HTTP 
		header, as well as all of the characters that form the structure of a 
		format or protocol. For example, <span class="qchar">&lt;</span> and <span class="qchar">
		&gt;</span>
          (as well as the element name and various attributes they surround) are 
		part of the syntactic content in an HTML document. </p>
        <p>Syntactic content usually is defined by a specification or 
		specifications and includes both the defined, reserved keywords for the 
		given protocol or format as well as string tokens and identifiers that 
		are defined by document authors to form the structure of the document 
		(rather than the "content" of the document).</p>
        <aside class="example">
          <p><cite>XML</cite> [[XML10]] defines specific elements, attributes, 
		  and values that are reserved across all XML documents. Thus, the word <code class="kw" translate="no">
		  encoding</code> has a defined meaning inside the XML document 
		  declaration: it is a reserved name. XML also allows a user to define 
		  elements and attributes for a given document, for example, by using a 
		  DTD. In a document that uses a DTD that defines an element called <code class="kw">
		  &lt;muffin&gt;</code>, <span class="qterm">muffin</span>
          is a part of the syntactic content.</p>
        </aside>
        <p><dfn>Natural language content</dfn> refers to the language-bearing 
		content in a document and <b>not</b> to any of the surrounding or 
		embedded syntactic content that form part of the document structure. You 
		can think of it as the actual "content" of the document or the "message" 
		in a given protocol. Note that syntactic content can contain natural 
		language content, such as when an [[HTML]] <code class="kw">img</code> 
		element has an <code class="kw">alt</code> attribute containing a 
		description of the image.</p>
          
        <p class="issue">Issue #59: should we use the term 'resource' in this 
		document using this definition, given the wider one in the more well 
		know RFC3986 URI spec.</p>
          
        <p>A <dfn data-lt="resource|resources">resource</dfn> is a given 
		document, file, or protocol "message" which includes both the <a>natural 
		language content</a> as well as the <a href="#def_syntactic_content" class="termref">
		syntactic content</a>
          such as identifiers surrounding or containing it. For example, in an 
		HTML document that also has some CSS and a few <code class="kw" translate="no">
		script</code>
          tags with embedded JavaScript, the entire HTML document, considered as 
		a file, is the resource.</p>
          
        <p>A <dfn data-lt="user value|user values">user value</dfn> is 
		unreserved syntactic content in a <a>vocabulary</a> that is assigned by 
		users, as distinct from reserved keywords in a given format or protocol. 
		For example, CSS class names are part of the syntax of a CSS style 
		sheet. They are not reserved keywords, predefined by any CSS 
		specification. They are subject to the syntactic rules of CSS. And they 
		may (or may not) consist of natural language tokens.</p>
          
        <p>A <dfn id="def_vocabulary">vocabulary</dfn> provides the list of 
		reserved names as well as the set of rules and specifications 
		controlling how <a>user values</a> (such as identifiers) can be assigned 
		in a format or protocol. This can include restrictions on range, order, 
		or type of characters that can appear in different places. For example, 
		HTML defines the names of its elements and attributes, as well as 
		enumerated attribute values, which defines the "vocabulary" of HTML
          <a href="#def_syntactic_content" class="termref">syntactic content</a>. 
		Another example would be ECMAScript, which restricts the range of 
		characters that can appear at the start or in the body of an identifier 
		or variable name. It applies different rules for other cases, such as to 
		the values of string literals.</p>
		
        <p>A <dfn data-lt="grapheme|graphemes">grapheme</dfn> is a sequence of 
		one or more Unicode characters in a visual representation of some text 
		that a typical user would perceive as being a single unit (<q>character</q>). 
		Graphemes are important for a number of text operations such as sorting 
		or text selection, so it is necessary to be able to compute the 
		boundaries between each user-perceived character. Unicode defines the 
		default mechanism for computing graphemes in <cite>Unicode Standard 
		Annex #29: Text Segmentation</cite> [[!UAX29]] and calls this 
		approximation a <dfn>grapheme cluster</dfn>. There are two types of 
		default grapheme cluster defined. Unless otherwise noted, grapheme 
		cluster in this document refers to an extended default grapheme cluster. 
		(A discussion of grapheme clusters is also given in Section 2 of the <cite>
		Unicode Standard</cite>, [[!Unicode]]. Cf. near the end of
           <a href="http://www.unicode.org/versions/Unicode8.0.0/ch02.pdf">
		Section 2.11</a>
           in version 8.0 of The Unicode Standard)</p>
        <p>Because different natural languages have different needs, grapheme 
		clusters can also sometimes require tailoring. For example, a Slovak 
		user might wish to treat the default pair of grapheme clusters "ch" as a 
		single grapheme cluster. Note that the interaction between the language 
		of string content and the end-user's preferences might be complex.</p>
        <section>
        <h5>Terminology Examples</h5>
        <p>This section illustrates some of the terminology defined above.</p>
          <div style="background-color:white;text-align: left; border-style: solid; border-width:3px; padding-left: 50px; padding-right: 50px; padding-top: 10px; width: 80%">
            <p> <span class="markup">&lt;<span class="vocabulary">html</span> <span class="vocabulary">
			lang</span>="en" <span class="vocabulary">dir</span>="<span class="vocabulary">ltr</span>"&gt;<br>
                &lt;<span class="vocabulary">head</span>&gt;</span></p>
            <p><span class="markup">&nbsp; &lt;<span class="vocabulary">meta</span> <span class="vocabulary">
			charset</span>="UTF-8"&gt;<br>
                &nbsp;&nbsp;&lt;<span class="vocabulary">title</span>&gt;</span><span class="shakespeare">Shakespeare</span><span

                class="markup">&lt;/<span class="vocabulary">title</span>&gt;<br>
                &lt;/<span class="vocabulary">head</span>&gt;<br>
                &lt;<span class="vocabulary">body</span>&gt;<br>
                &nbsp;&nbsp;&lt;<span class="vocabulary">img</span> <span class="vocabulary">
			src</span>="<span class="userValue">shakespeare.jpg</span>"
                <span class="vocabulary">alt</span>="<span class="userValue"><span class="shakespeare">William 
			Shakespeare</span></span>" <span class="vocabulary">id</span>="<span class="userValue">shakespeare_image</span>"&gt;<br>
                <br>
                &nbsp;&nbsp;&lt;<span class="vocabulary">p</span>&gt;</span><span class="shakespeare">What<span

                  class="markup">&amp;#x2019;</span>s in a name? That which we call 
			a rose by any other name would smell as sweet.</span><span

                class="markup">&lt;/<span class="vocabulary">p</span>&gt;<br>
                &lt;/<span class="vocabulary">body</span>&gt;<br>
                &lt;/<span class="vocabulary">html</span>&gt;</span> </p>
          </div>
          <ul style="text-align:left">
          <li>Everything inside the black rectangle (that is, in this HTML file) 
		  is part of the resource.</li>
          <li><a>Syntactic content</a> is shown in a <span class="markup">
		  monospaced font</span>.</li>
          <li><a>Natural language content</a> is shown in a <span class="shakespeare">
		  bold blue font with a gray background</span>.</li>
          <li>User values are shown in <span class="userValue">italics</span>.</li>
          <li><a>Vocabulary</a> is shown with <span class="vocabulary">red 
		  underlining</span>.</li>
          <li>All of the text above (all text in a text file) makes up a 
		  resource. It's possible that a given resource will contain no natural 
		  language content at all (consider an HTML document consisting of four 
		  empty <code>div</code> elements styled to be orange rectangles). It's 
		  also possible that a resource will contain
            <em>no</em> syntactic content and consist solely of natural language 
		  content: for example, a plain text file with a soliloquy from <cite>
		  Hamlet</cite>
            in it. Notice too that the HTML entity <code>&amp;#x2019;</code>
            appears in the natural language content and belongs to both the 
		  natural language content and the syntactic content in this resource.</li>
          </ul>
        </section>
      </section>
      <section id="conformance">
      <h3>Conformance</h3>
        <p>Where this specification contains a procedural description, it is to 
		be understood as a way to specify the desired external behavior. 
		Implementations can use other means of achieving the same results, as 
		long as observable behavior is not affected.</p>
      </section>
    </section>
    <section id="searching">
      <h2>String Searching in Natural Language Content</h2>
      <p>Many Web implementations and applications have a need for users or 
	  programs to search documents for particular words or phrases of natural 
	  language text. This is different from the sorts of programmatic matching 
	  needed by formal languages (such as markup languages such as [[HTML]]; 
	  style sheets [[CSS21]]; or data formats such as [[TURTLE]] or [[JSON-LD]]). </p>
      <p>There are many types of string searching. The form of string searching 
	  which we'll concern ourselves with here is sub-string matching or "find" 
	  operations. This is the direct searching of the body or "corpus" of a 
	  document with the user's input. Find operations can have different options 
	  or implementation details, such as the addition or removal of case 
	  sensitivity, or whether the feature supports different aspects of a 
	  regular expression language or "wildcards".</p>
      <p>A different type of string searching, <strong>which is outside the 
	  scope of this document</strong>, is <dfn>Full Text Search</dfn>. When you 
	  are using a search engine, you are generally using a form of full text 
	  search. Full text search generally breaks natural language text into word 
	  segments and may apply complex processing to get at the semantic "root" 
	  values of words. For example, if the user searches for "run", you might 
	  want to find words like "running", "ran", or "runs" in addition to the 
	  actual search term "run". This process, naturally, is sensitive to 
	  language, context, and many other aspects of textual variation. </p>
      <section id="searchingConsiderations">
        <h2>Considerations for Searching</h2>
        <p class="issue">This section was identified as a new area needing 
		document as part of the overall rearchitecting of the document. The text 
		here is incomplete and needs further development. Contributions from the 
		community are invited.</p>
		  <p>Implementers often need to provide simple "find text" algorithms 
		  and specifications often try to define APIs to support these needs. 
		  Find operations on text generate different user expectations and thus 
		  have different requirements from the need for absolute identity 
		  matching needed by document formats and protocols. It is important to 
		  note that domain-specific requirements may impose additional 
		  restrictions or alter the considerations presented here.</p>
		  <section id="UserInput">
		  <h3>Variations in User Input</h3>
        <p>One of the primary considerations for string searching is that, quite 
		often, the user's input is not identical to the way that the text being 
		searched is 
		encoded. </p>
			  <p>One primary reason this happens is because the text 
		can vary in ways the user cannot predict. In other cases it is because the user's keyboard 
		or input method does not provide ready access to the textual variations 
		needed&mdash;or because the user cannot be bothered to input the text accurately. For example,
		users often omit accents when entering Latin-script languages, particularly on mobile keyboards, even though the text they
		are searching includes the accents. In these cases, users generally expect the search operation to be more 
		"promiscuous" to make up for the failure to add additional effort to 
		their input. </p>
		  <p>For example, a user might expect a term entered in lowercase to 
		  match uppercase equivalents. Conversely, when the user expends more 
		  effort on the input&mdash;by using the shift key to produce uppercase or 
		  by entering a letter with diacritics instead of just the base 
		  letter&mdash;they might expect their search results to match (only) their 
		  more-specific input.</p>
		  <p>A different case is where the text can vary in multiple ways, but 
		  the user can only type a single search term in. For example, the 
		  Japanese language uses two different phonetic scripts, <em>hiragana</em> 
		  and <em>katakana</em>. These scripts encode the same phonemes; thus 
		  the user might expect that typing in a search term in <em>hiragana</em> 
		  would find the exact same word spelled out in <em>katakana</em>. </p>
			  <p>A 
		  different example might be the presence or absence of short vowels in 
		  the Arabic and Hebrew scripts. For most languages in these scripts, 
		  the inclusion of the short vowels is entirely optional, but the 
		  presence of vowels in text being searched might impede a match if the 
		  user doesn't enter or know to enter them.</p>
        <p>This effect might vary depending on context as well. For example, a 
		person using a physical keyboard may have direct access to accented 
		letters, while a virtual or on-screen keyboard may require extra effort 
		to access and select the same letters.</p>
        <p>Consider a document containing these strings: "re-resume", 
		"RE-RESUME", "re-r&#xe9;sum&#xe9;", and "RE-R&#xc9;SUM&#xc9;".</p>
        <p>In the table below, the user's input (on the left) might be 
		considered a match for the above items as follows:</p>
        <table class="data">
          <tbody>
            <tr>
              <th scope="col">User Input</th>
              <th scope="col">Matched Strings</th>
            </tr>
            <tr>
              <td>e (lowercase 'e')</td>
              <td>"re-resume", "RE-RESUME", "re-r&#xe9;sum&#xe9;", and "RE-R&#xC9;SUM&#xc9;"</td>
            </tr>
            <tr>
              <td>E (uppercase 'E')</td>
              <td>"RE-RESUME" and "RE-R&#xc9;SUM&#xc9;"</td>
            </tr>
            <tr>
              <td>&#xe9; (lowercase 'e' with acute accent)</td>
              <td>"re-r&#xe9;sum&#xe9;" and "RE-R&#xc9;SUM&#xc9;"</td>
            </tr>
            <tr>
              <td>&#xc9; (uppercase 'E' with acute accent)</td>
              <td>"RE-R&#xc9;SUM&#xc9;"</td>
            </tr>
          </tbody>
        </table>
        <p>In addition to variations of case or the use of accents, Unicode also 
		has an array of canonical equivalents or compatibility characters (as 
		described in the sections above) that might impact string searching.</p>
        <p>For example, consider the letter "K". Characters with a compatibility 
		mapping to <code>U+004B LATIN CAPITAL LETTER K</code> include:</p>
        <ol>
          <li>&#x136; U+0136</li>
          <li>&#x1e8; U+01E8</li>
          <li>&#x1d37; U+1D37</li>
          <li>&#x1e30; U+1E30</li>
          <li>&#x1e32; U+1E32</li>
          <li>&#x1e34; U+1E34</li>
          <li>&#x212a; U+212A</li>
          <li>&#x24c0; U+24C0</li>
          <li>&#x3385; U+3385</li>
          <li>&#x33cd; U+33CD</li>
          <li>&#x33ce; U+33CE</li>
          <li>&#xff2b; U+FF2B</li>
          <li>(a variety of mathematical symbols such as 
		  U+1D40A,U+1D43E,U+1D472,U+1D4A6,U+1D4DA)</li>
          <li>&#x1f11a; U+1F11A</li>
          <li>&#x1f13a; U+1F13A.</li>
        </ol>
        <p>Other differences include Unicode Normalization forms (or lack 
		thereof). There are also ignorable characters (such as the variation 
		selectors), whitespace differences, bidirectional controls, and other 
		code points that can interfere with a match. </p>
        <p>Users might also expect certain kinds of equivalence to be applied to 
		matching. For example, a Japanese user might expect that hiragana, 
		katakana, and half-width compatibility katakana equivalents all match 
		each other (regardless of which is used to perform the selection or 
		encoded in the text). </p>
        <p>When searching text, the concept of "grapheme boundaries" and 
		"user-perceived characters" can be important. See Section 3 of <cite>
		Character Model for the World Wide Web: Fundamentals</cite> [[!CHARMOD]] 
		for a description. For example, if the user has entered a capital "A" 
		into a search box, should the software find the character &#xc0; 
		(<span class="uname" translate="no">U+00C0 LATIN CAPITAL LETTER A WITH ACCENT GRAVE</span>)? 
		What about the character "A" followed by U+0300 (a combining accent 
		grave)? What about writing systems, such as Devanagari, which use 
		combining marks to suppress or express certain vowels?</p>
      </section>
      <section id="SearchOptions">
      <h3>Types of Search Option</h3>
      <p>When creating a string search API or algorithm, the following textual options might be useful to users:</p>
      <ul>
         <li>Case-sensitive vs. case-insensitive</li>
         <li>Kana folding</li>
         <li>Unicode normalization form</li>
         <li>etc.</li>
      </ul>
      </section>
    </section>
    </section>
    <section>
      <h2 id="Acknowledgements" class="informative">Acknowledgements</h2>
      <p>The W3C Internationalization Working Group and Interest Group, as well 
	  as others, provided many comments and suggestions. The Working Group would 
	  like to thank: all of the [[!CHARMOD]] contributors.. </p>
    </section>
  </body>
</html>
